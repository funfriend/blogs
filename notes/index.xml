<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Notes on Give me five</title>
    <link>/notes/</link>
    <description>Recent content in Notes on Give me five</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 10 Aug 2019 18:08:50 +0800</lastBuildDate>
    
	<atom:link href="/notes/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Substrate 第一印象</title>
      <link>/notes/first_impression_on_substrate/</link>
      <pubDate>Sat, 10 Aug 2019 18:08:50 +0800</pubDate>
      
      <guid>/notes/first_impression_on_substrate/</guid>
      <description>很早之前就听过 substrate 的大名，polkadot 也是基于 substrate 框架开发的，subsrate 想做一个通用的 blockchain 开发框架。 之前我也有过类似的想法。这么多的公链，讲道理 network，storage，consensus 等大部分的模块都是可以抽象出来，提供统一的接口供开发者做具体的实现。 这是题外话，说到 substrate，第一印象就是，WTF，怎么怎么多 macro？WTF，我的代码还要写在 macro 里面？WTF，这 tm 还是 Rust 吗？
看完下面这种代码。
decl_module!{pubstruct Module&amp;lt;T: Trait&amp;gt;forenum Callwhereorigin: T::Origin{/// The minimum period between blocks. Beware that this is different to the *expected* period /// that the block production apparatus provides. Your chosen consensus system will generally /// work with this to determine a sensible block time. e.g. For Aura, it will be double this /// period on default settings.</description>
    </item>
    
    <item>
      <title>Libra 源码</title>
      <link>/notes/libra/</link>
      <pubDate>Wed, 31 Jul 2019 23:43:04 +0800</pubDate>
      
      <guid>/notes/libra/</guid>
      <description>Storage storage 本身是一个 grpc 服务。
接口 module: storage/storage_service
提供的 grpc 接口：
service Storage { // Write APIs.  // Persist transactions. Called by Execution when either syncing nodes or  // committing blocks during normal operation.  rpc SaveTransactions(SaveTransactionsRequest) returns (SaveTransactionsResponse); // Read APIs.  // Used to get a piece of data and return the proof of it. If the client  // knows and trusts a ledger info at version v, it should pass v in as the  // client_known_version and we will return the latest ledger info together  // with the proof that it derives from v.</description>
    </item>
    
    <item>
      <title>mermory barrier 阅读笔记</title>
      <link>/notes/memory_order/</link>
      <pubDate>Thu, 14 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>/notes/memory_order/</guid>
      <description>https://mechanical-sympathy.blogspot.com/2011/07/memory-barriersfences.html 的阅读笔记。
memory barrier 保证 barrier 两边的指令执行结果可以以程序顺序的方式被其他 CPU 观察到。
store barrier:
 &amp;lsquo;sfence&amp;rsquo; instruction on x86, waits for all store instructions prior to the barrier to be written from the store buffer to the L1 cache for the CPU on which it is issued. All previous updates to memory that happened before the barrier are now visible.
 visible 只是说 数据写到 cache 了，但还不能保证其他 cpu 的 cache 也是最新的。
load barrier:</description>
    </item>
    
    <item>
      <title>关于 RocksDB 的 sub-compaction</title>
      <link>/notes/about-sub-compaction-in-rocksdb/</link>
      <pubDate>Sat, 15 Dec 2018 22:20:32 +0800</pubDate>
      
      <guid>/notes/about-sub-compaction-in-rocksdb/</guid>
      <description>之前我一直以为 sub-compaction 只会在 l0-&amp;gt; l1 生效。
今天观察线上 tikv 节点的 rocksdb log，发现 l2 -&amp;gt; l3 的 manual compaction，它的 sub compaction 竟然是 2。我配置的 tikv max_sub_compactions 也是 2。
看了 rocksdb(5.8.7) 的代码：
bool Compaction::ShouldFormSubcompactions() const { if (immutable_cf_options_.max_subcompactions &amp;lt;= 1 || cfd_ == nullptr) { return false; } if (cfd_-&amp;gt;ioptions()-&amp;gt;compaction_style == kCompactionStyleLevel) { return start_level_ == 0 &amp;amp;&amp;amp; output_level_ &amp;gt; 0 &amp;amp;&amp;amp; !IsOutputLevelEmpty(); } else if (cfd_-&amp;gt;ioptions()-&amp;gt;compaction_style == kCompactionStyleUniversal) { return number_levels_ &amp;gt; 1 &amp;amp;&amp;amp; output_level_ &amp;gt; 0; } else { return false; } }  上面只提到了 l0 -&amp;gt; ln。</description>
    </item>
    
    <item>
      <title>重读 Raft 论文</title>
      <link>/notes/raft-revisited/</link>
      <pubDate>Mon, 10 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>/notes/raft-revisited/</guid>
      <description>安全 如果一台机器应用了一条日志，那么其他的机器就无法应用具有相同ID但不同命令的日志。
Election Safety:
 At most one leader can be elected in a given term. §3.4
 Leader Append-Only:
 A leader never overwrites or deletes entries in its log; it only appends new entries. §3.5
 Log Matching:
 If two logs contain an entry with the same index and term, then the logs are identical in all entries up through the given index. §3.5
 Leader Completeness:</description>
    </item>
    
    <item>
      <title>Paper: A critique of snapshot isolation 笔记</title>
      <link>/notes/about_write_snapshot_isolation/</link>
      <pubDate>Tue, 04 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>/notes/about_write_snapshot_isolation/</guid>
      <description>Section 2  both write to row r 时间重叠：si &amp;lt; cj, ci &amp;gt; sj  介绍了 SI 的两种实现方式： - 基于锁的实现，拿 percolator 举例。 - 无锁的实现。没细看，跳过了。
Section 3: Serializablility 首先说明了 SI 的问题：
 避免 Write-Write 冲突不足够实现 Serializablility。有 write skew 的问题。 同时也不是实现 Serializablility 的必要条件。禁止了一些事实上是 Serializable 的操作。  Section 4: Read-Write vs Write-Write 从 read-snapshot isolation 出发定义了 write-snapshot isolation：
 txn2 修改了 txn1 读的数据。 s1 &amp;lt; c2, c1 &amp;gt; c2  得出结论： - 避免 Read-Write 冲突可以实现 Serializablility。 - 但同样也禁止了一些是 Serializable 的操作。</description>
    </item>
    
    <item>
      <title>Paper: A critique of ANSI SQL isolation levels 笔记</title>
      <link>/notes/about_isolation/</link>
      <pubDate>Mon, 10 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>/notes/about_isolation/</guid>
      <description>P1(Dirty Read): 脏读 w1[x] ... r2[x] ...   txn1 修改了一行数据。（未 commit 之前） txn2 读到修改的值。（未commit 之前）  P2(Fuzz or Non-repeatable Read): 不可重读 r1[x] ... w2[x] ... c2 ... r1[x] ... c1   txn1 读了一个数据， txn2 修改这个数据，并 commit txn1 重新读这个数据，读到新的值。  P3(Phantom): 幻读 r1[P] ... w2[y in P] ... c2 ... r1[P] ... c1   txn1 读了一段满足某个 condition 的数据， txn2 修改了一条数据，使之满足或者不满足这个 condition（比如说删掉了一条满足 condition 的数据，新增了一条满足 condition 数据），并 commit。 txn1 重新读满足这个 condition 的数据，返回数据变化。  P2 可以看做是 P3 的特殊 case。</description>
    </item>
    
    <item>
      <title>JDBC loadbalance 模式的小坑</title>
      <link>/notes/a-strange-behavior-in-jdbc-loadbalance-mode-using-tidb/</link>
      <pubDate>Wed, 08 Aug 2018 22:38:50 +0800</pubDate>
      
      <guid>/notes/a-strange-behavior-in-jdbc-loadbalance-mode-using-tidb/</guid>
      <description>昨天在写代码插入数据到 tidb 的时候，时不时报错说 connection closed。一直没找到原因。 今天梳理代码，发现了这个坑。
用 jdbc 连接 tidb 的时候，
 配置了 jdbc:mysql:loadbalance 模式（后面有多台 tidb，暂时还没有 load balance，只能先通过这种方式来搞）。 然后 jdbc 连接中没有显式的配置用哪个库。  这个时候，mysql client 底层在做 loadblance 的时候，会把之前 connection 的状态 sync 到新的 connection 上。这里面包括了：
 auto commit catalog isolation level max rows  void syncSessionState(Connection source, Connection target, boolean readOnly) throws SQLException { if (target != null) { target.setReadOnly(readOnly); } if (source == null || target == null) { return; } boolean prevUseLocalSessionState = source.</description>
    </item>
    
    <item>
      <title>TiKV scheduler 的流程图</title>
      <link>/notes/tidb-scheduler/</link>
      <pubDate>Thu, 10 May 2018 00:00:00 +0000</pubDate>
      
      <guid>/notes/tidb-scheduler/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Tikv 的参数调优</title>
      <link>/notes/tikv-params-optimization/</link>
      <pubDate>Sun, 08 Apr 2018 22:51:24 +0800</pubDate>
      
      <guid>/notes/tikv-params-optimization/</guid>
      <description>Manual Compaction TiKV 有一个后台任务定期去对 region 做Compact，每次 100个 region。见：store.on_comact_check_tick。
落到 RocksDB里面就是很多个 CompactRange 操作。见： compact.rs
如果业务场景是频繁的写更新，一次 tick 就会产生多个 compact_range 操作。 而 RocksDB 在 CompactRange 时会做一次 flush。 如果某次 compact range 的次数过多，会引起 level-0 的sst 来不急 compaction，引起 write_stall。
参考：
 http://kernelmaker.github.io/Rocksdb_Study_4 http://kernelmaker.github.io/Rocksdb_Study_5 http://alexstocks.github.io/html/rocksdb.html  系统参数 fs： dirty_background_ratio 和 dirty_ratio
参考：
 https://www.jianshu.com/p/027f681f59e6  bytes-per-sync https://github.com/tikv/tikv/issues/2675</description>
    </item>
    
    <item>
      <title>TiDB 的 Update 操作</title>
      <link>/notes/update-in-tidb/</link>
      <pubDate>Wed, 28 Feb 2018 22:46:26 +0800</pubDate>
      
      <guid>/notes/update-in-tidb/</guid>
      <description>今天突然想起来一个点：当提交过来的 Update 操作中涉及到了索引列，且列的新值与旧值相同，这个时候，不需要更新对应的索引数据。 好奇 TiDB 是否做了这个优化，于是过了一下对应的代码。
涉及的代码包括：
 https://github.com/pingcap/tidb/blob/master/executor/write.go https://github.com/pingcap/tidb/blob/master/table/tables/tables.go  大致流程是这样的，
 先通过 SelectPlan 把需要 update 的数据行从 TiKV 中拿出来，将行中需要修改的字段找出，标记为 assigned。（看到这里，我还以为 TiDB 没有做，差点就没忍住去提 Issue 了） 在 updateRecord 方法中，又进一步对上述被标记为 assigned 的字段做判定，判断是否真的被 modified 了。规则是：比较新值和旧值，如果不相等，才标记为 modified。 做完了上面这个事情，如果真的存在修改，再对表中的 OnUpdateNow 的字段做处理。 准备完数据后，接下来就是把 column 更新后的值写入到底层 Storage 中。这段代码在 Table.UpdateRecord 实现中。忽略 binlog 的处理，其实就是更新索引列的数据（删除旧的，增加新的），以及更新主表的数据。  就是不知道 Phoenix 做 Upsert 时，有没有这个优化。如果没有，那问题就大啦！ 每次 Upsert，无论数据是不是真的被修改掉，都需要去做 Write 操作。而 Phoenix 的跨行事务垃圾的很，很容易出问题。</description>
    </item>
    
    <item>
      <title>一个好的配置中心应该有什么</title>
      <link>/notes/what-a-good-confserver-should-have/</link>
      <pubDate>Tue, 13 Jun 2017 23:14:51 +0800</pubDate>
      
      <guid>/notes/what-a-good-confserver-should-have/</guid>
      <description> 服务端  更改可以准实时同步到客户端，两种主要方式。  配置中心推送到客户端，实现方式？ 客户端对配置中心轮询。  完善的管理功能。  管理多个环境下多个服务的多个版本的配置。 提供 Typed Config Properties。 提供 USER 管理，GROUP 管理。不同 GROUP/USER 看到的是不同的环境和服务配置。 最好，配置中心可以和服务发现机制相结合，能够提供更多的功能。比如说： 灰度发布，A/B test，流量控制 等等。  能够知晓当前服务的状况。 比如说有某个服务有多少个客户端。 客户端使用的事哪个版本的配置。 能够知晓配置更新的状态。比如， 新的配置在哪些客户端生效了，哪些客户端没有响应，没响应的客户端要不要重新推送配置。 HA ?  HA 主要影响的是配置中心到底需要使用什么数据库。 比如说 MySQL, ETCD, ZK，或者其他。   客户端  可能需要针对不同语言实现不同的客户端。 客户端启动的时候，将自己注册到配置中心，表明自己对哪个服务的那个版本的配置感兴趣。 然后拉取最新的配置，缓存到本地内存。 保持和配置中心的连接，发送心跳信息，（TCP，或者HTTP WebSocket, 或者 Long Polling ） 配置中心有更新推送过来的时候，更新本地内存。 optional，定时去配置中心拉取配置。  调研  QConf: zk DisConf: zk Spring Cloud Config: 基于 git/file/vault Apollo: 携程开源的基于 eureka Netflix/archaius: a java library support config dynamic changed from external sources, like zk, etcd  </description>
    </item>
    
    <item>
      <title>why ruby is dying</title>
      <link>/notes/why-ruby-is-dying/</link>
      <pubDate>Sat, 24 Dec 2016 00:00:00 +0000</pubDate>
      
      <guid>/notes/why-ruby-is-dying/</guid>
      <description>Lack of multi threads. Concurrency is hard, especially in ruby. Many other languages like Rust, Elixir, Scala, Clojure make multi-core programming easy. These fancy things cannot exists in Ruby because of GIL. Go http://awesome-ruby.com/#awesome-ruby-concurrency, and you can see only three libraries there, and difficult to use. Lack of basic type constraints. (One thing I like Elixir/Erlang most is optional type definitions.) Type is the new sexy:  Many languages based on JVM are typed.</description>
    </item>
    
    <item>
      <title>ROP 错误处理</title>
      <link>/notes/railway-oriented-programming/</link>
      <pubDate>Sun, 14 Aug 2016 00:00:00 +0000</pubDate>
      
      <guid>/notes/railway-oriented-programming/</guid>
      <description>常见的错误处理方法 try-catch begin ## send post request rescue NetworkError =&amp;gt; e end return code ret = send_post_request() if ret.code != 0 return error else parse(ret.data) end 存在的问题 复杂的业务逻辑:
 验证用户输入 数据库访问 文件访问 网络问题 &amp;hellip;  如果在业务逻辑中，使用上述的处理方法，代码很容易变丑，添加各种 if 判断，各种 begin-rescue。
Enter ROP(Railway Oriented Programming) =&amp;gt;
如果 Validate 失败，就不执行 UpdateDb 操作， 如果 UpdateDb 失败，就不执行 SendEmail 操作。
实现：
Try = Struct.new(:ok, data_or_exception) class Try def pipe(&amp;amp;block) if !@ok return self end block.call(@data_or_exception) end end def validate(req) # do your validation Try.</description>
    </item>
    
    <item>
      <title>毕业季找工作</title>
      <link>/notes/job-finding/</link>
      <pubDate>Mon, 21 Sep 2015 00:00:00 +0000</pubDate>
      
      <guid>/notes/job-finding/</guid>
      <description> 找工作 最近大半个月的经历 阅兵假回来北京之后，一头扎进了找工作的大军之中。 第一天收到了腾讯的笔试邀请，当时没怎么重视，开考半个多小时才开始做题目。 一看题目傻眼了，这些大学计算机知识点，大部分都忘的一干二净，尤其是那些坑人的 C++ 技术点。 当时没放在心上，随便做了下，现在想来，即使重视了，也不一定做的好。 学渣呀。
期间陆陆续续投了大概 10 多家互联网公司，像网易，美团，今日头条，滴滴等等。 做了三四次笔试，题目差不多，基本全挂。
有尝试去了解一些创业团队，在知乎、哪上班、简寻上面留有简历。 面谈了几家公司，聊的比较开心。
今天电面了云巴，被面试官批评基础知识不牢固。 这里的基础知识，指的是大学期间的一些基础课程，如操作系统，计算机网络等等。 事实确实是这样，这些知识的系统性学习是在大三期间，之后没有深入研习过，三四年过去了，怎么可能扎实。
大概就是这样。当然其中省略了很多，比如说和几家创业团队的面聊，这里暂且不表。
有什么发现 发现倒是不少。
 大公司的校招处处是坑。 大部分所谓的技术型公司都是挂羊头买狗肉。 这个世界的某些角落，是有那么一撮人在做着从 0 到 1 的事情。至少我遇见了两个。 90 后还是和 90 后聊的最开心呀！ 找工作真的像相亲一样，一定要找臭味相投的那种。装逼高冷的就算了吧！  想要什么 就我个人而言，时间是最值钱的东西，任何能提高效率的都是我想追求的。 而一个优秀的 team 是最能接近这个目标的。 当然，生活在世，还少不了钱！
给自己的一些建议  戒骄戒躁。 保持健身。 多看书，多思考。 多看代码，多实践。 爱自己，爱女票。  </description>
    </item>
    
    <item>
      <title>TLP in Scala</title>
      <link>/notes/type-level-programming/</link>
      <pubDate>Sat, 13 Jun 2015 00:00:00 +0000</pubDate>
      
      <guid>/notes/type-level-programming/</guid>
      <description>Concepts  Dependent Type Abstract Type type keyword
 Phantom Type, used as type constraints but never instantiated.
 Implicit Parameter/Conversion
  trait Printer[T] { def print(t: T): String } implicit val sp: Printer[Int] = new Printer[Int] { def print(i :Int) = i.toString } def foo[T](t: T)(implicit p: Printer[T]) = p.print(t)  Type Class  trait CanFoo[A] { def foos(x: A): String } case class Wrapper(wrapped: String) object WrapperCanFoo extends CanFoo[Wrapper] { def foos(x: Wrapper) = x.</description>
    </item>
    
    <item>
      <title>关于 Lambda Architecture</title>
      <link>/notes/lambda-architecture/</link>
      <pubDate>Fri, 04 Jul 2014 20:37:49 +0800</pubDate>
      
      <guid>/notes/lambda-architecture/</guid>
      <description>Refer:
 http://lambda-architecture.net http://nathanmarz.com/blog/how-to-beat-the-cap-theorem.html http://radar.oreilly.com/2014/07/questioning-the-lambda-architecture.html  Update1 Lambda architecture is ugly, and it&amp;rsquo;s already solved by Google dataflow model, See apache beam and dataflow paper.</description>
    </item>
    
    <item>
      <title>Scala 基础笔记</title>
      <link>/notes/scala-basics/</link>
      <pubDate>Sat, 10 Aug 2013 00:25:23 +0800</pubDate>
      
      <guid>/notes/scala-basics/</guid>
      <description>控制结构和函数  赋值动作本身是没有值的。  var a = 1 scala&amp;gt; val nn = (a+=1) nn: Unit = ()  scala 支持函数。只要函数不是递归的，就不需要指定返回类型。 异常中 throw 有特殊的类型 Nothing。  类、对象以及特质  下面代码中，_ 是什么意思？  class Person { var name: String = _ }  类型投影？ 在内嵌类中访问外部类？ 定义只读属性时,  val attr private var privateAttr + def attar = privateAttr   选择哪个？其他更好的方案？
 类的伴生对象，可以访问类的私有成员。 类和其伴生对象可以相互访问私有特性？ 单例对象和伴生对象的关系？ 扩展类  使用 extends 关键字扩展类。 可以将类、字段、方法声明为 final，以确保其不会被重写。注：java 中的 final 意思与 val 类似，表示不可变。  重写方法  使用 override 修饰符来重写一个 非抽象方法 （那抽象方法？）。 使用 super 关键字来调用超类的方法。  类型检查和转换  o.</description>
    </item>
    
    <item>
      <title>Loop and a half 问题</title>
      <link>/notes/loop-and-a-half/</link>
      <pubDate>Fri, 29 Mar 2013 00:31:12 +0800</pubDate>
      
      <guid>/notes/loop-and-a-half/</guid>
      <description>大部分的循环形式可以总结如下：
A: S; if B then goto Z fi; T; goto A; Z: // do other stuff  当 S 为空时，可以写成 while 循环：until B do T;； 当 T 为空时，可以写成 do-while 循环：repeat S; until B;。
但是，当 S 和 T 都不为空时，无论是写成 while 还是 do-while 总会有多余的一部分在循环之外执行：
S; until B do begin T; S; end  inversedT; repeat T; S; until B;  这就是所谓的 loop and a half 问题。（相信大家在编程过程中都有遇到过）
诸如：repeat begin S; when B exit; T; end 中这样的 loop/break 控制语句被添加到现代编程语言中，以解决 消除 goto 所带来的不便。</description>
    </item>
    
    <item>
      <title></title>
      <link>/notes/about_libra/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/notes/about_libra/</guid>
      <description>build install deps:
brew install cmake protobuf go  Chain Move Language concept: - address: 256 bit bytes. - resource: instance of resource type. - module: contain resouce type defs and procedure defs.
Bytecode verifier  control-flow graph construction. stack balance checking. type checking. Kind checking: based on rules about resource types.  resource cannot be duplicated. resource cannot be destroyed. resource must be used.  Reference checking. (will be another paper on this) Linking: check struct types and procedures.</description>
    </item>
    
  </channel>
</rss>